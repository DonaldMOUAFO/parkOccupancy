{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fb9d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 10:19:57.670573: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-12 10:19:57.816262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 10:19:58.605765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from src.infrastructure import acpds\n",
    "from src.domain.engine import train_model\n",
    "from src.model import rcnn, fast_rcnn_fpn\n",
    "\n",
    "torch.cuda.empty_cache() # not recommanded to call by end user by pytorch\n",
    "\n",
    "# torch.backends.cudnn.benchmark if True,  it enables benchmark mode in cudnn which is good whenever the input sizes for the network do not vary. This way, cudnn look for the optimal set of algorithms for that particular \n",
    "# configuration (which takes some time). This usually leads to faster runtime. But if your input sizes changes at each iteration, then cudnn will benchmark every time a new size appears, \n",
    "# possibly leading to worse runtime performances.\n",
    "# torch.backends.cudnn.benchmark = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d266c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print( torch.cuda.is_available() )  # True si GPU détecté\n",
    "print( torch.cuda.device_count() )  # nombre total de GPU disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01262de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 GPU(s) detected\n",
      "0 CPU(s) detected\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-12 10:20:48.316493: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-12 10:20:48.317810: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('gpu')\n",
    "cpus = tf.config.list_physical_devices('cpu')\n",
    "print(len(gpus), \"GPU(s) detected\")\n",
    "print(len(cpus), \"CPU(s) detected\")\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "\n",
    "for cpu in cpus:\n",
    "    print(cpu)\n",
    "\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4baa9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annotations.json', 'images']\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "data_url = \"../../data/parking_rois_gopro\"\n",
    "print(os.listdir(data_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a40ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "divice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# divice = \"cpu\"\n",
    "print( f\"Using device: {divice}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1983575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of TORCH / TF train dataset: 231/231\n",
      "Length of TORCH / TF val dataset: 35/35\n",
      "Length of TORCH / TF test dataset: 27/27\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "train_ds, val_ds, test_ds = acpds.create_datasets(data_url)\n",
    "\n",
    "train_ds_tf, val_ds_tf, test_ds_tf = acpds.create_datasets_tf(data_url)\n",
    "\n",
    "# train_ds, val_ds, test_ds are instances of torch.utils.data.dataloader.DataLoader\n",
    "# print length of each dataset\n",
    "print(f\"Length of TORCH / TF train dataset: {len(train_ds)}/{len(train_ds_tf)}\")\n",
    "print(f\"Length of TORCH / TF val dataset: {len(val_ds)}/{len(val_ds_tf)}\")\n",
    "print(f\"Length of TORCH / TF test dataset: {len(test_ds)}/{len(test_ds_tf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab0afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besttic-rd/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'backbone_name' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/besttic-rd/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/besttic-rd/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = fast_rcnn_fpn.FasterRCNN_FPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59cba114",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.float32)\n",
    "# train_ds = train_ds.to(torch.float32)\n",
    "# val_ds   = train_ds.to(torch.float32)\n",
    "# test_ds  = train_ds.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b583b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/FasterRCNN_FPN_1762791114.6586063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besttic-rd/Documents/besttic/parkOccupancy/src/infrastructure/acpds.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  image = torch.tensor(image, dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "output_dir = \"../../data/\" + model._get_name() + \"_\" + str(now)\n",
    "print(output_dir)\n",
    "\n",
    "train_model(model, train_ds, val_ds, test_ds, output_dir, device=divice, epochs=10, verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb4c5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/FasterRCNN_FPN_1762939457.0602252'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = time.time()\n",
    "output_dir = \"../../data/\" + model._get_name() + \"_\" + str(now)\n",
    "output_dir                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_ds, val_ds, test_ds, output_dir, device=divice, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81c6a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e394ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68a265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in string format\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a371a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64, 64, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([64, 256, 1, 1])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([512, 128, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([1024, 512, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([1024, 256, 1, 1])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([2048, 1024, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([512, 2048, 1, 1])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([2048, 512, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2048, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([1024, 12544])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024, 1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([2, 1024])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters() :\n",
    "    #if not isinstance(parm, torch.nn.parameter.Parameter):\n",
    "    print( param.shape )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
